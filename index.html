<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Sparse-Adapters</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
<!--   <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Exploring Sparse Adapters for Scalable Merging of Parameter Efficient Experts</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://saminyeasar.github.io">Samin Yeasar Arnob</a><sup>1,2,6</sup>,</span>
            <span class="author-block">
              <a href="">Zhan Su</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="">Minseon Kim</a><sup>6</sup>,</span>
            <span class="author-block">
              <a href="">Oleksiy Ostapenko</a><sup>5</sup>,</span>
            <span class="author-block">
              <a href="">Esraâ€™a Saleh</a><sup>2,3</sup>,</span>
            <span class="author-block">
              <a href="https://riyasatohib.com">Riyasat Ohib</a><sup>4</sup>,</span>
            <span class="author-block">
              <a href="https://mila.quebec/en/directory/doina-precup">Doina Precup</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="">Lucas Page-Caccia</a><sup>6</sup>,</span>
            <span class="author-block">
              <a href="https://www.microsoft.com/en-us/research/people/alsordon/">Alessandro Sordoni</a><sup>6</sup>,</span>

          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>McGill University,</span>
            <span class="author-block"><sup>2</sup>Mila Quebec AI Institute,</span>
            <span class="author-block"><sup>3</sup>Universite de Montreal,</span>
            <span class="author-block"><sup>4</sup>Georgia Institute of Technology,</span>
            <span class="author-block"><sup>5</sup>ServiceNow,</span>
            <span class="author-block"><sup>6</sup>Microsoft Research</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openreview.net/pdf?id=te7UC87Zbw"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/SaminYeasar/sparse_adapter"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/sparse_adapter_fig.png" alt="Teaser Image" style="height: 100%;" />
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Model merging aims to integrate knowledge from multiple task experts into a single, unified multi-task model. Parameter-efficient adaptation, namely 
          LoRA, have become the de-facto approach to obtain memory-friendly task experts. In this paper, we study the properties of sparse adapters, which
          train only a subset of weights in the base neural network, as potential adaptation recipe for downstream model merging. First, we propose a simple
          method for training highly effective sparse adapters, which surprisingly outperforms both LoRA and full fine-tuning in our setting. 
          Next, we investigate the merging properties of these sparse adapters, merging up to 20 natural language processing task adapters. 
          Our findings demonstrate that sparse adapters yield superior in-distribution performance post-merging
          compared to LoRA or full model merging. Achieving strong held-out performance remains a challenge for all methods considered.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
       <img src="./static/images/spad_fig2.png" alt="Teaser Image" style="height: 100%;" />
       <img src="./static/images/spad_fig3.png" alt="Teaser Image" style="height: 100%;" />
       <img src="./static/images/spad_fig4.png" alt="Teaser Image" style="height: 100%;" />
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/Poster_sparse_adapter.png" alt="Teaser Image" style="height: 150%;" />
    </div>
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @inproceedings{
arnob2025exploring,
title={Exploring Sparse Adapters for Scalable Merging of Parameter Efficient Experts},
author={Samin Yeasar Arnob and Zhan Su and Minseon Kim and Oleksiy Ostapenko and Riyasat Ohib and Esra'a Saleh and Doina Precup and Lucas Caccia and Alessandro Sordoni},
booktitle={Second Conference on Language Modeling},
year={2025},
url={https://openreview.net/forum?id=te7UC87Zbw}
}
    </code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
